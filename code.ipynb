{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NASA Exoplanet Mass Prediction\n",
        "\n",
        "This notebook predict Mass of a exoplanet using NASA Exoplanet Archive data"
      ],
      "metadata": {
        "id": "8o58onG8zI5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and Setup"
      ],
      "metadata": {
        "id": "z-Iqqur_zY4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from scipy import stats\n",
        "from scipy.stats import jarque_bera, normaltest, shapiro, chi2_contingency\n",
        "from statsmodels.stats.diagnostic import het_white, het_breuschpagan\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, QuantileTransformer, PolynomialFeatures, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, RFE, RFECV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, VotingRegressor, StackingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "from sklearn.inspection import permutation_importance\n",
        "import itertools\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "EcxfbiZYzKGK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Initial Inspection"
      ],
      "metadata": {
        "id": "vfgfEZHvzm7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync?query=select+*+from+ps&format=csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "print(\"\\nColumn Data Types:\")\n",
        "print(df.dtypes.value_counts())\n",
        "\n",
        "target_col = 'pl_bmasse'\n",
        "print(f\"\\nTarget variable '{target_col}' statistics:\")\n",
        "print(df[target_col].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7QQPVs1zn1o",
        "outputId": "00bd3668-2f8c-429a-fa88-a16d38cec81f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (38898, 354)\n",
            "Memory usage: 291.88 MB\n",
            "\n",
            "Column Data Types:\n",
            "float64    239\n",
            "object      89\n",
            "int64       26\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Target variable 'pl_bmasse' statistics:\n",
            "count     6866.000000\n",
            "mean       710.053607\n",
            "std       1451.794928\n",
            "min          0.015000\n",
            "25%         13.300000\n",
            "50%        190.000000\n",
            "75%        664.979818\n",
            "max      25426.400000\n",
            "Name: pl_bmasse, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Quality Assessment and Missing Value Analysis"
      ],
      "metadata": {
        "id": "w7dTAY_Hzwl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_stats = pd.DataFrame({\n",
        "    'Column': df.columns,\n",
        "    'Missing_Count': df.isnull().sum(),\n",
        "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
        "    'Data_Type': df.dtypes\n",
        "})\n",
        "missing_stats = missing_stats[missing_stats['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
        "\n",
        "relevant_features = ['pl_bmasse', 'pl_rade', 'pl_orbper', 'pl_orbsmax', 'pl_eqt',\n",
        "                    'st_mass', 'st_rad', 'st_teff', 'st_met', 'st_age', 'st_dens',\n",
        "                    'pl_dens', 'discoverymethod', 'disc_year', 'sy_dist']\n",
        "\n",
        "df_filtered = df[relevant_features].copy()\n",
        "\n",
        "df_clean = df_filtered.dropna(subset=[target_col])\n",
        "\n",
        "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "for col in numeric_cols:\n",
        "    if col != target_col:\n",
        "        df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
        "\n",
        "print(f\"Clean dataset shape: {df_clean.shape}\")\n",
        "print(f\"Remaining missing values: {df_clean.isnull().sum().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eyMkR9Tz0vg",
        "outputId": "a14dfab2-0df0-4ac6-8514-933f052daece"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean dataset shape: (6866, 15)\n",
            "Remaining missing values: 0\n"
          ]
        }
      ]
    }
  ]
}